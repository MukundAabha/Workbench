{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date and time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are creating a bunch of new columns using the datetime column. Let’s see some of the sample features that can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aabha Gupta\\AppData\\Local\\Temp\\ipykernel_17700\\2194283564.py:11: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  \"weekofyear\": s.dt.weekofyear.values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# create a series of datetime with a frequency of 10 hours\n",
    "s = pd.date_range('2020-01-06', '2020-01-10', freq='10H').to_series()\n",
    "# create some features based on datetime\n",
    "features = {\n",
    " \"dayofweek\": s.dt.dayofweek.values,\n",
    " \"dayofyear\": s.dt.dayofyear.values,\n",
    " \"hour\": s.dt.hour.values,\n",
    " \"is_leap_year\": s.dt.is_leap_year.values,\n",
    " \"quarter\": s.dt.quarter.values,\n",
    " \"weekofyear\": s.dt.weekofyear.values\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using aggregates in pandas, it is quite easy to create features like these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    " # create a bunch of features using the date column\n",
    " df.loc[:, 'year'] = df['date'].dt.year\n",
    " df.loc[:, 'weekofyear'] = df['date'].dt.weekofyear\n",
    " df.loc[:, 'month'] = df['date'].dt.month\n",
    " df.loc[:, 'dayofweek'] = df['date'].dt.dayofweek\n",
    " df.loc[:, 'weekend'] = (df['date'].dt.weekday >=5).astype(int)\n",
    " \n",
    " # create an aggregate dictionary\n",
    " aggs = {}\n",
    " # for aggregation by month, we calculate the\n",
    " # number of unique month values and also the mean\n",
    " aggs['month'] = ['nunique', 'mean']\n",
    " aggs['weekofyear'] = ['nunique', 'mean']\n",
    " # we aggregate by num1 and calculate sum, max, min \n",
    " # and mean values of this column\n",
    " aggs['num1'] = ['sum','max','min','mean']\n",
    " # for customer_id, we calculate the total count\n",
    " aggs['customer_id'] = ['size']\n",
    " # again for customer_id, we calculate the total unique\n",
    " aggs['customer_id'] = ['nunique']\n",
    " \n",
    " # we group by customer_id and calculate the aggregates\n",
    " agg_df = df.groupby('customer_id').agg(aggs)\n",
    " agg_df = agg_df.reset_index()\n",
    " return agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## statistical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, for example, when dealing with time-series problems, you might have \n",
    "features which are not individual values but a list of values. For example, \n",
    "transactions by a customer in a given period of time. In these cases, we create \n",
    "different types of features such as: with numerical features, when you are grouping \n",
    "on a categorical column, you will get features like a list of values which are time \n",
    "distributed. In these cases, you can create a bunch of statistical features such as:\n",
    "- Mean\n",
    "- Max\n",
    "- Min\n",
    "- Unique\n",
    "- Skew\n",
    "- Kurtosis\n",
    "- Kstat\n",
    "- Percentile\n",
    "- Quantile\n",
    "- Peak to peak\n",
    "- And many more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aabha Gupta\\Work\\AAAMLP\\feature_engineering.ipynb Cell 8\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m feature_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# calculate mean\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m feature_dict[\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# calculate max\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m feature_dict[\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature_dict = {}\n",
    "# calculate mean\n",
    "feature_dict['mean'] = np.mean(x)\n",
    "# calculate max\n",
    "feature_dict['max'] = np.max(x)\n",
    "# calculate min\n",
    "feature_dict['min'] = np.min(x)\n",
    "# calculate standard deviation\n",
    "feature_dict['std'] = np.std(x)\n",
    "# calculate variance\n",
    "feature_dict['var'] = np.var(x)\n",
    "# peak-to-peak\n",
    "feature_dict['ptp'] = np.ptp(x)\n",
    "# percentile features\n",
    "feature_dict['percentile_10'] = np.percentile(x, 10)\n",
    "feature_dict['percentile_60'] = np.percentile(x, 60)\n",
    "feature_dict['percentile_90'] = np.percentile(x, 90)\n",
    "# quantile features\n",
    "feature_dict['quantile_5'] = np.quantile(x, 0.05)\n",
    "feature_dict['quantile_95'] = np.quantile(x, 0.95)\n",
    "feature_dict['quantile_99'] = np.quantile(x, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series data (list of values) can be converted to a lot of features. \n",
    "A python library called tsfresh is instrumental in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tsfresh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aabha Gupta\\Work\\AAAMLP\\feature_engineering.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtsfresh\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_calculators \u001b[39mas\u001b[39;00m fc\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# tsfresh based features\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aabha%20Gupta/Work/AAAMLP/feature_engineering.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m feature_dict[\u001b[39m'\u001b[39m\u001b[39mabs_energy\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fc\u001b[39m.\u001b[39mabs_energy(x)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tsfresh'"
     ]
    }
   ],
   "source": [
    "from tsfresh.feature_extraction import feature_calculators as fc\n",
    "# tsfresh based features\n",
    "feature_dict['abs_energy'] = fc.abs_energy(x)\n",
    "feature_dict['count_above_mean'] = fc.count_above_mean(x)\n",
    "feature_dict['count_below_mean'] = fc.count_below_mean(x)\n",
    "feature_dict['mean_abs_change'] = fc.mean_abs_change(x)\n",
    "feature_dict['mean_change'] = fc.mean_change(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " tsfresh offers hundreds of features and tens of variations of different \n",
    "features that you can use for time series (list of values) based features. In the \n",
    "examples above, x is a list of values. But that’s not all. There are many other features \n",
    "that you can create for numerical data with or without categorical data. A simple \n",
    "way to generate many features is just to create a bunch of polynomial features. For \n",
    "example, a second-degree polynomial feature from two features “a” and “b” would \n",
    "include: “a”, “b”, “ab”, “a2\n",
    "” and “b2\n",
    "”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# generate a random dataframe with \n",
    "# 2 columns and 100 rows\n",
    "df = pd.DataFrame(\n",
    " np.random.rand(100, 2),\n",
    " columns=[f\"f_{i}\" for i in range(1, 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385130</td>\n",
       "      <td>0.224575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912021</td>\n",
       "      <td>0.443297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641941</td>\n",
       "      <td>0.992088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.685992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.805110</td>\n",
       "      <td>0.933088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.837821</td>\n",
       "      <td>0.783369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.485438</td>\n",
       "      <td>0.585550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.926228</td>\n",
       "      <td>0.359476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.518330</td>\n",
       "      <td>0.348956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.290085</td>\n",
       "      <td>0.850618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f_1       f_2\n",
       "0   0.385130  0.224575\n",
       "1   0.912021  0.443297\n",
       "2   0.641941  0.992088\n",
       "3   0.005152  0.685992\n",
       "4   0.805110  0.933088\n",
       "..       ...       ...\n",
       "95  0.837821  0.783369\n",
       "96  0.485438  0.585550\n",
       "97  0.926228  0.359476\n",
       "98  0.518330  0.348956\n",
       "99  0.290085  0.850618\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can create two-degree polynomial features using PolynomialFeatures from \n",
    "scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# initialize polynomial features class object\n",
    "# for two-degree polynomial features\n",
    "pf = preprocessing.PolynomialFeatures(\n",
    " degree=2,\n",
    " interaction_only=False,\n",
    " include_bias=False\n",
    ")\n",
    "# fit to the features\n",
    "pf.fit(df)\n",
    "# create polynomial features\n",
    "poly_feats = pf.transform(df)\n",
    "# create a dataframe with all the features\n",
    "num_feats = poly_feats.shape[1]\n",
    "df_transformed = pd.DataFrame(\n",
    " poly_feats,\n",
    " columns=[f\"f_{i}\" for i in range(1, num_feats + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385130</td>\n",
       "      <td>0.224575</td>\n",
       "      <td>0.148325</td>\n",
       "      <td>0.086491</td>\n",
       "      <td>0.050434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912021</td>\n",
       "      <td>0.443297</td>\n",
       "      <td>0.831782</td>\n",
       "      <td>0.404296</td>\n",
       "      <td>0.196512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641941</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>0.412088</td>\n",
       "      <td>0.636862</td>\n",
       "      <td>0.984239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.685992</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.470585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.805110</td>\n",
       "      <td>0.933088</td>\n",
       "      <td>0.648203</td>\n",
       "      <td>0.751239</td>\n",
       "      <td>0.870653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_1       f_2       f_3       f_4       f_5\n",
       "0  0.385130  0.224575  0.148325  0.086491  0.050434\n",
       "1  0.912021  0.443297  0.831782  0.404296  0.196512\n",
       "2  0.641941  0.992088  0.412088  0.636862  0.984239\n",
       "3  0.005152  0.685992  0.000027  0.003534  0.470585\n",
       "4  0.805110  0.933088  0.648203  0.751239  0.870653"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you create third-degree \n",
    "polynomial features, you will end up with nine features in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting feature converts the numbers to categories. It’s known as \n",
    "binning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins of the numerical columns\n",
    "# 10 bins\n",
    "df[\"f_bin_10\"] = pd.cut(df[\"f_1\"], bins=10, labels=False)\n",
    "# 100 bins\n",
    "df[\"f_bin_100\"] = pd.cut(df[\"f_1\"], bins=100, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_bin_10</th>\n",
       "      <th>f_bin_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385130</td>\n",
       "      <td>0.224575</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912021</td>\n",
       "      <td>0.443297</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641941</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.685992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.805110</td>\n",
       "      <td>0.933088</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_1       f_2  f_bin_10  f_bin_100\n",
       "0  0.385130  0.224575         3         38\n",
       "1  0.912021  0.443297         9         91\n",
       "2  0.641941  0.992088         6         64\n",
       "3  0.005152  0.685992         0          0\n",
       "4  0.805110  0.933088         8         80"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance without and with the log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08612085456683241"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.f_3.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04424523282580211"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.f_3.apply(lambda x: np.log(1 + x)).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancy way of filling in the missing values would be to use a k-nearest neighbour\n",
    "method. You can select a sample with missing values and find the nearest \n",
    "neighbours utilising some kind of distance metric, for example, Euclidean distance. \n",
    "Then you can take the mean of all nearest neighbours and fill up the missing value. \n",
    "You can use the KNN imputer implementation for filling missing values like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8. ,  8.5, 14. , 10. , 12. ,  6.5],\n",
       "       [ 6. , 11. , 12. ,  7. , 10. ,  3. ],\n",
       "       [ 6. ,  8. , 14. , 12. , 13. , 10. ],\n",
       "       [ 5. ,  8. ,  5. , 14. , 11. ,  4. ],\n",
       "       [ 5.5,  6. ,  9.5, 14. , 12.5,  9. ],\n",
       "       [14. ,  3. ,  6. ,  8. ,  5. ,  6. ],\n",
       "       [ 8. , 10. , 10. ,  3. ,  9. ,  6. ],\n",
       "       [ 8. ,  9.5,  8. , 13. , 12. ,  4. ],\n",
       "       [ 8. , 14. ,  7. ,  8.5,  5. , 13. ],\n",
       "       [ 7. ,  4. ,  1. ,  8. , 12. , 11. ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import impute\n",
    "# create a random numpy array with 10 samples\n",
    "# and 6 features and values ranging from 1 to 15\n",
    "X = np.random.randint(1, 15, (10, 6))\n",
    "# convert the array to float\n",
    "X = X.astype(float)\n",
    "# randomly assign 10 elements to NaN (missing)\n",
    "X.ravel()[np.random.choice(X.size, 10, replace=False)] = np.nan\n",
    "# use 2 nearest neighbours to fill na values\n",
    "knn_imputer = impute.KNNImputer(n_neighbors=2)\n",
    "knn_imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a3043d4dc251bedbbd01c29590a92d37eed389d9c1f7ebfef3c61c680315891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
