{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662feb4d",
   "metadata": {},
   "source": [
    "The simplest form of selecting features would be to remove features with very \n",
    "low variance. If the features have a very low variance (i.e. very close to 0), they \n",
    "are close to being constant and thus, do not add any value to any model at all. It \n",
    "would just be nice to get rid of them and hence lower the complexity. Please note \n",
    "that the variance also depends on scaling of the data. Scikit-learn has an \n",
    "implementation for VarianceThreshold that does precisely this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa61fe9",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "data = ...\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "transformed_data = var_thresh.fit_transform(data)\n",
    "\n",
    "#### transformed data will have all columns with variance less than 0.1 removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f925169",
   "metadata": {},
   "source": [
    "We can also remove features which have a high correlation. For calculating the \n",
    "correlation between different numerical features, you can use the Pearson \n",
    "correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba8ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedInc_Sqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119034</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.062040</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>-0.079809</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>0.984329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>-0.119034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>-0.077747</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>-0.132797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847621</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>0.106389</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>0.326688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>-0.062040</td>\n",
       "      <td>-0.077747</td>\n",
       "      <td>0.847621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066197</td>\n",
       "      <td>-0.006181</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>-0.066910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>0.004834</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>-0.066197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069863</td>\n",
       "      <td>-0.108785</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.018415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>0.018766</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>-0.006181</td>\n",
       "      <td>0.069863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.015266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>-0.079809</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.106389</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>-0.108785</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.924664</td>\n",
       "      <td>-0.084303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>-0.924664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedInc_Sqrt</th>\n",
       "      <td>0.984329</td>\n",
       "      <td>-0.132797</td>\n",
       "      <td>0.326688</td>\n",
       "      <td>-0.066910</td>\n",
       "      <td>0.018415</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>-0.084303</td>\n",
       "      <td>-0.015569</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "MedInc       1.000000 -0.119034  0.326895  -0.062040    0.004834  0.018766   \n",
       "HouseAge    -0.119034  1.000000 -0.153277  -0.077747   -0.296244  0.013191   \n",
       "AveRooms     0.326895 -0.153277  1.000000   0.847621   -0.072213 -0.004852   \n",
       "AveBedrms   -0.062040 -0.077747  0.847621   1.000000   -0.066197 -0.006181   \n",
       "Population   0.004834 -0.296244 -0.072213  -0.066197    1.000000  0.069863   \n",
       "AveOccup     0.018766  0.013191 -0.004852  -0.006181    0.069863  1.000000   \n",
       "Latitude    -0.079809  0.011173  0.106389   0.069721   -0.108785  0.002366   \n",
       "Longitude   -0.015176 -0.108197 -0.027540   0.013344    0.099773  0.002476   \n",
       "MedInc_Sqrt  0.984329 -0.132797  0.326688  -0.066910    0.018415  0.015266   \n",
       "\n",
       "             Latitude  Longitude  MedInc_Sqrt  \n",
       "MedInc      -0.079809  -0.015176     0.984329  \n",
       "HouseAge     0.011173  -0.108197    -0.132797  \n",
       "AveRooms     0.106389  -0.027540     0.326688  \n",
       "AveBedrms    0.069721   0.013344    -0.066910  \n",
       "Population  -0.108785   0.099773     0.018415  \n",
       "AveOccup     0.002366   0.002476     0.015266  \n",
       "Latitude     1.000000  -0.924664    -0.084303  \n",
       "Longitude   -0.924664   1.000000    -0.015569  \n",
       "MedInc_Sqrt -0.084303  -0.015569     1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# fetch a regression dataset\n",
    "data = fetch_california_housing()\n",
    "X = data[\"data\"]\n",
    "col_names = data[\"feature_names\"]\n",
    "y = data[\"target\"]\n",
    "# convert to pandas dataframe\n",
    "df = pd.DataFrame(X, columns=col_names)\n",
    "# introduce a highly correlated column\n",
    "df.loc[:, \"MedInc_Sqrt\"] = df.MedInc.apply(np.sqrt)\n",
    "# get correlation matrix (pearson)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e754f61",
   "metadata": {},
   "source": [
    "#### We see that the feature MedInc_Sqrt has a very high correlation with MedInc. We can thus remove one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd50103",
   "metadata": {},
   "source": [
    "### Univariate feature selection\n",
    "is nothing but a scoring of each feature against a given target. Mutual information, ANOVA F-test and chi2 are some of the most popular methods for univariate feature selection. There are two ways of using these in scikit\u0002learn.\n",
    "\n",
    "- SelectKBest: It keeps the top-k scoring features\n",
    "- SelectPercentile: It keeps the top features which are in a percentage specified by the user\n",
    "\n",
    "It must be noted that you can use chi2 only for data which is non-negative in nature. \n",
    "This is a particularly useful feature selection technique in natural language \n",
    "processing when we have a bag of words or tf-idf based features. Itâ€™s best to create \n",
    "a wrapper for univariate feature selection that you can use for almost any new \n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0826e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "class UnivariateFeatureSelction:\n",
    "    def __init__(self, n_features, problem_type, scoring):\n",
    "        \"\"\"\n",
    " Custom univariate feature selection wrapper on\n",
    " different univariate feature selection models from\n",
    " scikit-learn.\n",
    " :param n_features: SelectPercentile if float else SelectKBest\n",
    " :param problem_type: classification or regression\n",
    " :param scoring: scoring function, string\n",
    "        \"\"\"\n",
    " # for a given problem type, there are only\n",
    " # a few valid scoring methods\n",
    " # you can extend this with your own custom\n",
    " # methods if you wish\n",
    "        if problem_type == \"classification\":\n",
    "            valid_scoring = {\"f_classif\": f_classif,\"chi2\": chi2,\"mutual_info_classif\": mutual_info_classif}\n",
    "        else:\n",
    "            valid_scoring = {\"f_regression\": f_regression,\"mutual_info_regression\": mutual_info_regression}\n",
    " \n",
    " # raise exception if we do not have a valid scoring method\n",
    "        if scoring not in valid_scoring:\n",
    "            raise Exception(\"Invalid scoring function\")\n",
    " \n",
    " # if n_features is int, we use selectkbest\n",
    " # if n_features is float, we use selectpercentile\n",
    " # please note that it is int in both cases in sklearn\n",
    "        if isinstance(n_features, int):\n",
    "            self.selection = SelectKBest(valid_scoring[scoring],k=n_features)\n",
    "        elif isinstance(n_features, float):\n",
    "            self.selection = SelectPercentile(valid_scoring[scoring],percentile=int(n_features * 100))\n",
    "        else:\n",
    "            raise Exception(\"Invalid type of feature\")\n",
    " \n",
    " # same fit function\n",
    "    def fit(self, X, y):\n",
    "        return self.selection.fit(X, y)\n",
    " \n",
    " # same transform function\n",
    "    def transform(self, X):\n",
    "        return self.selection.transform(X)\n",
    " \n",
    " # same fit_transform function\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.selection.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c2c659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the class\n",
    "\n",
    "ufs = UnivariateFeatureSelction(n_features=0.1, problem_type=\"regression\", scoring=\"f_regression\")\n",
    "ufs.fit(X, y)\n",
    "X_transformed = ufs.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6269e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
