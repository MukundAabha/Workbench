{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e35531",
   "metadata": {},
   "source": [
    "If we talk about classification problems, the most common metrics used are:\n",
    "- Accuracy\n",
    "- Precision (P)\n",
    "- Recall (R)\n",
    "- F1 score (F1)\n",
    "- Area under the ROC (Receiver Operating Characteristic) curve or simply AUC (AUC)\n",
    "- Log loss\n",
    "- Precision at k (P@k)\n",
    "- Average precision at k (AP@k)\n",
    "- Mean average precision at k (MAP@k)\n",
    "When it comes to regression, the most commonly used evaluation metrics are:\n",
    "- Mean absolute error (MAE)\n",
    "- Mean squared error (MSE)\n",
    "- Root mean squared error (RMSE)\n",
    "- Root mean squared logarithmic error (RMSLE)\n",
    "- Mean percentage error (MPE)\n",
    "- Mean absolute percentage error (MAPE)\n",
    "- R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f060dc",
   "metadata": {},
   "source": [
    "### Accuracy: \n",
    "\n",
    "It is one of the most straightforward metrics used in machine learning. It defines how accurate your model is. if you \n",
    "build a model that classifies 90 images accurately, your accuracy is 90% or 0.90. If only 83 images are classified correctly, the accuracy of your model is 83% or 0.83. \n",
    "Simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57c4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate accuracy\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: accuracy score\n",
    " \"\"\"\n",
    " # initialize a simple counter for correct predictions\n",
    " correct_counter = 0\n",
    " # loop over all elements of y_true\n",
    " # and y_pred \"together\"\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            # if prediction is equal to truth, increase the counter\n",
    "            correct_counter += 1\n",
    "            # return accuracy\n",
    "            # which is correct predictions over the number of samples\n",
    "            return correct_counter / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7d39a",
   "metadata": {},
   "source": [
    "Now, let’s say we change the dataset a bit such that there are 180 chest x-ray images \n",
    "which do not have pneumothorax and only 20 with pneumothorax. Even in this \n",
    "case, we will create the training and validation sets with the same ratio of positive \n",
    "to negative (pneumothorax to non- pneumothorax) targets. In each set, we have 90 \n",
    "non- pneumothorax and 10 pneumothorax images. If you say that all images in the \n",
    "validation set are non-pneumothorax, what would your accuracy be? Let’s see; you\n",
    "classified 90% of the images correctly. So, your accuracy is 90%. \n",
    "\n",
    "But look at it one more time. \n",
    "\n",
    "You didn’t even build a model and got an accuracy of 90%. That seems kind of \n",
    "useless. If we look carefully, we will see that the dataset is skewed, i.e., the number \n",
    "of samples in one class outnumber the number of samples in other class by a lot. In \n",
    "these kinds of cases, it is not advisable to use accuracy as an evaluation metric as it \n",
    "is not representative of the data. So, you might get high accuracy, but your model \n",
    "will probably not perform that well when it comes to real-world samples, and you \n",
    "won’t be able to explain to your managers why.\n",
    "\n",
    "In these cases, it’s better to look at other metrics such as precision. \n",
    "Before learning about precision, we need to know a few terms. Here we have \n",
    "assumed that chest x-ray images with pneumothorax are positive class (1) and \n",
    "without pneumothorax are negative class (0).\n",
    "\n",
    "True positive (TP): Given an image, if your model predicts the image has \n",
    "pneumothorax, and the actual target for that image has pneumothorax, it is \n",
    "considered a true positive.\n",
    "\n",
    "True negative (TN): Given an image, if your model predicts that the image does not \n",
    "have pneumothorax and the actual target says that it is a non-pneumothorax image, \n",
    "it is considered a true negative.\n",
    "\n",
    "In simple words, if your model correctly predicts positive class, it is true positive, \n",
    "and if your model accurately predicts negative class, it is a true negative.\n",
    "\n",
    "False positive (FP): Given an image, if your model predicts pneumothorax and the \n",
    "actual target for that image is non- pneumothorax, it a false positive.\n",
    "\n",
    "False negative (FN): Given an image, if your model predicts non-pneumothorax \n",
    "and the actual target for that image is pneumothorax, it is a false negative.\n",
    "\n",
    "In simple words, if your model incorrectly (or falsely) predicts positive class, it is \n",
    "a false positive. If your model incorrectly (or falsely) predicts negative class, it is a \n",
    "false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa506fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate True Positives\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: number of true positives\n",
    " \"\"\"\n",
    " # initialize\n",
    " tp = 0\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    " return tp\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate True Negatives\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: number of true negatives\n",
    " \"\"\"\n",
    " # initialize\n",
    " tn = 0\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    " return tn\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate False Positives\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: number of false positives\n",
    " \"\"\"\n",
    " # initialize\n",
    " fp = 0\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    " return fp\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate False Negatives\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: number of false negatives\n",
    " \"\"\"\n",
    " # initialize\n",
    " fn = 0\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    " return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9108eeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "true_positive(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1be252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3f01cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c959ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negative(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499414de",
   "metadata": {},
   "source": [
    "If we have to define accuracy using the terms described above, we can write:\n",
    "Accuracy Score = (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690214f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_v2(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate accuracy using tp/tn/fp/fn\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: accuracy score\n",
    " \"\"\"\n",
    " tp = true_positive(y_true, y_pred)\n",
    " fp = false_positive(y_true, y_pred)\n",
    " fn = false_negative(y_true, y_pred)\n",
    " tn = true_negative(y_true, y_pred)\n",
    " accuracy_score = (tp + tn) / (tp + tn + fp + fn)\n",
    " return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de799b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f942e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aad79d",
   "metadata": {},
   "source": [
    "Precision is defined as:\n",
    "Precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68c45c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate precision\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: precision score\n",
    " \"\"\"\n",
    " tp = true_positive(y_true, y_pred)\n",
    " fp = false_positive(y_true, y_pred)\n",
    " precision = tp / (tp + fp)\n",
    " return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b0df425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6d677",
   "metadata": {},
   "source": [
    "Recall is defined as:\n",
    "Recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc7adde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate recall\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: recall score\n",
    " \"\"\"\n",
    " tp = true_positive(y_true, y_pred)\n",
    " fn = false_negative(y_true, y_pred)\n",
    " recall = tp / (tp + fn)\n",
    " return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b9dd3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " recall(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10892227",
   "metadata": {},
   "source": [
    "And that matches our calculated value!\n",
    "\n",
    "For a “good” model, our precision and recall values should be high. We see that in \n",
    "the above example, the recall value is quite high. However, precision is very low! \n",
    "Our model produces quite a lot of false positives but less false negatives. Fewer\n",
    "false negatives are good in this type of problem because you don’t want to say that \n",
    "\n",
    "patients do not have pneumothorax when they do. That is going to be more harmful. \n",
    "But we do have a lot of false positives, and that’s not good either.\n",
    "Most of the models predict a probability, and when we predict, we usually choose \n",
    "this threshold to be 0.5. This threshold is not always ideal, and depending on this \n",
    "threshold, your value of precision and recall can change drastically. If for every \n",
    "threshold we choose, we calculate the precision and recall values, we can create a \n",
    "plot between these sets of values. This plot or curve is known as the precision-recall \n",
    "curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43ade4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "y_pred = [0.02638412, 0.11114267, 0.31620708, 0.0490937, 0.0191491, 0.17554844,0.15952202, \n",
    "          0.03819563, 0.11639273, 0.079377, 0.08584789, 0.39095342, 0.27259048, 0.03447096,\n",
    "          0.04644807,0.03543574, 0.18521942, 0.05934905, 0.61977213, 0.33056815]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0779194",
   "metadata": {},
   "source": [
    "So, y_true is our targets, and y_pred is the probability values for a sample being \n",
    "assigned a value of 1. So, now, we look at probabilities in prediction instead of the \n",
    "predicted value (which is most of the time calculated with a threshold at 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8afd2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# how we assumed these thresholds is a long story\n",
    "thresholds = [0.0490937 , 0.05934905, 0.079377, 0.08584789, 0.11114267, 0.11639273, \n",
    "              0.15952202, 0.17554844, 0.18521942, 0.27259048, 0.31620708, 0.33056815, 0.39095342, 0.61977213]\n",
    "\n",
    "# for every threshold, calculate predictions in binary\n",
    "# and append calculated precisions and recalls\n",
    "# to their respective lists\n",
    "\n",
    "for i in thresholds:\n",
    " temp_prediction = [1 if x >= i else 0 for x in y_pred]\n",
    " p = precision(y_true, temp_prediction)\n",
    " r = recall(y_true, temp_prediction)\n",
    " precisions.append(p)\n",
    " recalls.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c10f6d",
   "metadata": {},
   "source": [
    "Now, we can plot these values of precisions and recalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1a2661f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Precision')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall', fontsize=15)\n",
    "plt.ylabel('Precision', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc67f0",
   "metadata": {},
   "source": [
    "You will notice that it’s challenging to choose a value of threshold that gives both \n",
    "good precision and recall values. If the threshold is too high, you have a smaller\n",
    "number of true positives and a high number of false negatives. This decreases your \n",
    "recall; however, your precision score will be high. If you reduce the threshold too \n",
    "low, false positives will increase a lot, and precision will be less.\n",
    "\n",
    "Both precision and recall range from 0 to 1 and a value closer to 1 is better.\n",
    "\n",
    "F1 score is a metric that combines both precision and recall. It is defined as a simple \n",
    "weighted average (harmonic mean) of precision and recall. If we denote precision \n",
    "using P and recall using R, we can represent the F1 score as:\n",
    "\n",
    "F1 = 2PR / (P + R)\n",
    "\n",
    "A little bit of mathematics will lead you to the following equation of F1 based on \n",
    "\n",
    "TP, FP and FN\n",
    "\n",
    "F1 = 2TP / (2TP + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4cced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate f1 score\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: f1 score\n",
    " \"\"\"\n",
    " p = precision(y_true, y_pred)\n",
    " r = recall(y_true, y_pred)\n",
    " score = 2 * p * r / (p + r)\n",
    " return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e4f72bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "y_pred = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a693010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce2a32",
   "metadata": {},
   "source": [
    "Instead of looking at precision and recall individually, you can also just look at F1\n",
    "score. Same as for precision, recall and accuracy, F1 score also ranges from 0 to 1,\n",
    "and a perfect prediction model has an F1 of 1. When dealing with datasets that have \n",
    "skewed targets, we should look at F1 (or precision and recall) instead of accuracy.\n",
    "\n",
    "Then there are other crucial terms that we should know about. \n",
    "\n",
    "The first one is TPR or True Positive Rate, which is the same as recall.\n",
    "TPR = TP / (TP + FN)\n",
    "\n",
    "TPR or recall is also known as sensitivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52a5dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate tpr\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: tpr/recall\n",
    " \"\"\"\n",
    " return recall(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d791e",
   "metadata": {},
   "source": [
    "And FPR or False Positive Rate, which is defined as:\n",
    "\n",
    "FPR = FP / (TN + FP)\n",
    "\n",
    "And 1 - FPR is known as specificity or True Negative Rate or TNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3b3efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate fpr\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: fpr\n",
    " \"\"\"\n",
    " fp = false_positive(y_true, y_pred)\n",
    " tn = true_negative(y_true, y_pred)\n",
    " return fp / (tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13325a",
   "metadata": {},
   "source": [
    "These are a lot of terms, but the most important ones out of these are only TPR and \n",
    "FPR. \n",
    "\n",
    "Let’s assume that we have only 15 samples and their target values are binary:\n",
    "Actual targets : [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
    "\n",
    "We train a model like the random forest, and we can get the probability of when a \n",
    "sample is positive.\n",
    "\n",
    "\n",
    "Predicted probabilities for 1: [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, \n",
    "0.2, 0.85, 0.15, 0.99]\n",
    "\n",
    "For a typical threshold of >= 0.5, we can evaluate all the above values of precision, \n",
    "recall/TPR, F1 and FPR. But we can do the same if we choose the value of the \n",
    "threshold to be 0.4 or 0.6. In fact, we can choose any value between 0 and 1 and \n",
    "calculate all the metrics described above.\n",
    "\n",
    "Let’s calculate only two values, though: TPR and FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1e24457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to store tpr \n",
    "# and fpr values\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "# actual targets\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1, \n",
    " 0, 0, 1, 0, 1, 0, 0, 1]\n",
    "# predicted probabilities of a sample being 1\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, \n",
    " 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, \n",
    " 0.85, 0.15, 0.99]\n",
    "# handmade thresholds\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    " 0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
    "# loop over all thresholds\n",
    "for thresh in thresholds: \n",
    " # calculate predictions for a given threshold\n",
    " temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    " # calculate tpr\n",
    " temp_tpr = tpr(y_true, temp_pred)\n",
    " # calculate fpr\n",
    " temp_fpr = fpr(y_true, temp_pred)\n",
    " # append tpr and fpr to lists\n",
    " tpr_list.append(temp_tpr)\n",
    " fpr_list.append(temp_fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d121e7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.fill_between(fpr_list, tpr_list, alpha=0.4)\n",
    "plt.plot(fpr_list, tpr_list, lw=3)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel('FPR', fontsize=15)\n",
    "plt.ylabel('TPR', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad36059",
   "metadata": {},
   "source": [
    "This curve is also known as the Receiver Operating Characteristic (ROC). And \n",
    "if we calculate the area under this ROC curve, we are calculating another metric \n",
    "which is used very often when you have a dataset which has skewed binary targets. \n",
    "This metric is known as the Area Under ROC Curve or Area Under Curve or \n",
    "just simply AUC. There are many ways to calculate the area under the ROC curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75d880db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8300000000000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " metrics.roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb6073",
   "metadata": {},
   "source": [
    "AUC values range from 0 to 1.\n",
    "\n",
    "- AUC = 1 implies you have a perfect model. Most of the time, it means that \n",
    "you made some mistake with validation and should revisit data processing \n",
    "and validation pipeline of yours. If you didn’t make any mistakes, then \n",
    "congratulations, you have the best model one can have for the dataset you \n",
    "built it on.\n",
    "\n",
    "- AUC = 0 implies that your model is very bad (or very good!). Try inverting \n",
    "the probabilities for the predictions, for example, if your probability for the \n",
    "positive class is p, try substituting it with 1-p. This kind of AUC may also \n",
    "mean that there is some problem with your validation or data processing.\n",
    "\n",
    "- AUC = 0.5 implies that your predictions are random. So, for any binary \n",
    "\n",
    "classification problem, if I predict all targets as 0.5, I will get an AUC of \n",
    "0.5.\n",
    "AUC values between 0 and 0.5 imply that your model is worse than random. Most \n",
    "of the time, it’s because you inverted the classes. If you try to invert your \n",
    "predictions, your AUC might become more than 0.5. AUC values closer to 1 are \n",
    "considered good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b96841",
   "metadata": {},
   "source": [
    "But what does AUC say about our model? \n",
    "\n",
    "Suppose you get an AUC of 0.85 when you build a model to detect pneumothorax \n",
    "from chest x-ray images. This means that if you select a random image from your \n",
    "dataset with pneumothorax (positive sample) and another random image without \n",
    "pneumothorax (negative sample), then the pneumothorax image will rank higher \n",
    "than a non-pneumothorax image with a probability of 0.85.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e14b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to store true positive \n",
    "# and false positive values\n",
    "tp_list = []\n",
    "fp_list = []\n",
    "# actual targets\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
    "# predicted probabilities of a sample being 1\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]\n",
    "# some handmade thresholds\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
    "# loop over all thresholds\n",
    "for thresh in thresholds: \n",
    "# calculate predictions for a given threshold\n",
    " temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    " # calculate tp\n",
    " temp_tp = true_positive(y_true, temp_pred)\n",
    " # calculate fp\n",
    " temp_fp = false_positive(y_true, temp_pred)\n",
    " # append tp and fp to lists\n",
    " tp_list.append(temp_tp)\n",
    " fp_list.append(temp_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fba79dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.fill_between(fp_list, tp_list, alpha=0.4)\n",
    "plt.plot(fp_list, tp_list, lw=3)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel('FPR', fontsize=15)\n",
    "plt.ylabel('TPR', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add894c8",
   "metadata": {},
   "source": [
    "Most of the time, the top-left value on ROC curve should give you a quite good \n",
    "threshold, as shown in figure ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a3031",
   "metadata": {},
   "source": [
    "Another important metric you should learn after learning AUC is log loss. In case \n",
    "of a binary classification problem, we define log loss as:\n",
    "\n",
    "Log Loss = - 1.0 * ( target * log(prediction) + (1 - target) * log(1 - prediction) )\n",
    "\n",
    "Where target is either 0 or 1 and prediction is a probability of a sample belonging \n",
    "to class 1.\n",
    "\n",
    "For multiple samples in the dataset, the log-loss over all samples is a mere average \n",
    "of all individual log losses. One thing to remember is that log loss penalizes quite \n",
    "high for an incorrect or a far-off prediction, i.e. log loss punishes you for being very \n",
    "sure and very wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e63f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def log_loss(y_true, y_proba):\n",
    "    \n",
    " \"\"\"\n",
    " Function to calculate log loss\n",
    " :param y_true: list of true values\n",
    " :param y_proba: list of probabilities for 1\n",
    " :return: overall log loss\n",
    " \"\"\"\n",
    " # define an epsilon value\n",
    " # this can also be an input\n",
    " # this value is used to clip probabilities\n",
    " epsilon = 1e-15\n",
    " # initialize empty list to store\n",
    " # individual losses\n",
    " loss = []\n",
    " # loop over all true and predicted probability values\n",
    " for yt, yp in zip(y_true, y_proba):\n",
    " # adjust probability\n",
    " # 0 gets converted to 1e-15\n",
    " # 1 gets converted to 1-1e-15\n",
    " # Why? Think about it!\n",
    "     yp = np.clip(yp, epsilon, 1 - epsilon)\n",
    "     # calculate loss for one sample\n",
    "     temp_loss = - 1.0 * (yt * np.log(yp) + (1 - yt) * np.log(1 - yp))\n",
    "     # add to loss list\n",
    "     loss.append(temp_loss)\n",
    " # return mean loss over all samples\n",
    " return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f6b3da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49882711861432294"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 0, 0, 1, 0, 1,0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_proba = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2,0.85, 0.15, 0.99]\n",
    "log_loss(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f8f03",
   "metadata": {},
   "source": [
    "We can compare this with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7d60583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49882711861432294"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782373c",
   "metadata": {},
   "source": [
    "Thus, our implementation is correct. Implementation of log loss is easy. \n",
    "Interpretation may seem a bit difficult. You must remember that log loss penalizes \n",
    "a lot more than other metrics. \n",
    "For example, if you are 51% sure about a sample belonging to class 1, log loss \n",
    "would be:\n",
    "\n",
    "- 1.0 * ( 1 * log(0.51) + (1 - 1) * log(1 – 0.51) ) = 0.67\n",
    "\n",
    "And if you are 49% sure for a sample belonging to class 0, log loss would be:\n",
    "\n",
    "- 1.0 * ( 0 * log(0.49) + (1 - 0) * log(1 – 0.49) ) = 0.67\n",
    "\n",
    "So, even though we can choose a cut off at 0.5 and get perfect predictions, we will \n",
    "still have a very high log loss. So, when dealing with log loss, you need to be very \n",
    "careful; any non-confident prediction will have a very high log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79b440",
   "metadata": {},
   "source": [
    "There are three different ways to calculate this which might get confusing from time \n",
    "to time. Let’s assume we are interested in precision first. We know that precision \n",
    "depends on true positives and false positives.\n",
    "\n",
    "- Macro averaged precision: calculate precision for all classes individually \n",
    "and then average them\n",
    "- Micro averaged precision: calculate class wise true positive and false \n",
    "positive and then use that to calculate overall precision\n",
    "- Weighted precision: same as macro but in this case, it is weighted average \n",
    "depending on the number of items in each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a667ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def macro_precision(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate macro averaged precision\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: macro precision score\n",
    " \"\"\"\n",
    " \n",
    " # find the number of classes by taking\n",
    " # length of unique values in true list\n",
    " num_classes = len(np.unique(y_true))\n",
    " \n",
    " # initialize precision to 0\n",
    " precision = 0\n",
    " \n",
    " # loop over all classes\n",
    " for class_ in range(num_classes):\n",
    " \n",
    " # all classes except current are considered negative\n",
    "     temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "     temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    " \n",
    " # calculate true positive for current class\n",
    "     tp = true_positive(temp_true, temp_pred)\n",
    " \n",
    " # calculate false positive for current class\n",
    "     fp = false_positive(temp_true, temp_pred)\n",
    " \n",
    " # calculate precision for current class\n",
    "     temp_precision = tp / (tp + fp)\n",
    " \n",
    " # keep adding precision for all classes\n",
    "     precision += temp_precision\n",
    " # calculate and return average precision over all classes\n",
    "     precision /= num_classes\n",
    " return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f9700e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def micro_precision(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate micro averaged precision\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: micro precision score\n",
    " \"\"\"\n",
    " \n",
    " # find the number of classes by taking\n",
    " # length of unique values in true list\n",
    " num_classes = len(np.unique(y_true))\n",
    " \n",
    " # initialize tp and fp to 0\n",
    " tp = 0\n",
    " fp = 0\n",
    " \n",
    " # loop over all classes\n",
    " for class_ in range(num_classes):\n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    " \n",
    " # calculate true positive for current class\n",
    " # and update overall tp\n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    " \n",
    " # calculate false positive for current class\n",
    " # and update overall tp\n",
    "        fp += false_positive(temp_true, temp_pred)\n",
    " \n",
    " # calculate and return overall precision\n",
    " precision = tp / (tp + fp)\n",
    " return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7087f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let’s look at the implementation of weighted precision.\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "def weighted_precision(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate weighted averaged precision\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: weighted precision score\n",
    " \"\"\"\n",
    " \n",
    " # find the number of classes by taking\n",
    " # length of unique values in true list\n",
    " num_classes = len(np.unique(y_true))\n",
    " \n",
    " # create class:sample count dictionary\n",
    " # it looks something like this:\n",
    " # {0: 20, 1:15, 2:21}\n",
    " class_counts = Counter(y_true)\n",
    " \n",
    " # initialize precision to 0\n",
    " precision = 0\n",
    " \n",
    " # loop over all classes\n",
    " for class_ in range(num_classes):\n",
    " # all classes except current are considered negative\n",
    "     temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "     temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    " \n",
    " # calculate tp and fp for class\n",
    "     tp = true_positive(temp_true, temp_pred)\n",
    "     fp = false_positive(temp_true, temp_pred)\n",
    " \n",
    " # calculate precision of class\n",
    "     temp_precision = tp / (tp + fp)\n",
    " \n",
    " # multiply precision with count of samples in class\n",
    "     weighted_precision = class_counts[class_] * temp_precision\n",
    " \n",
    " # add to overall precision\n",
    "     precision += weighted_precision\n",
    " # calculate overall precision by dividing by\n",
    " # total number of samples\n",
    "     overall_precision = precision / len(y_true)\n",
    "\n",
    " return overall_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb44ca48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39814814814814814"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "macro_precision(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e97dc479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_true, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "078df91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_precision(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57816f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_true, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48992453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39814814814814814"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_precision(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "792f9c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39814814814814814"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_true, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59839044",
   "metadata": {},
   "source": [
    "Similarly, we can implement the recall metric for multi-class. Precision and recall \n",
    "depend on true positive, false positive and false negative while F1 depends on \n",
    "precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7eeef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "def weighted_f1(y_true, y_pred):\n",
    " \"\"\"\n",
    " Function to calculate weighted f1 score\n",
    " :param y_true: list of true values\n",
    " :param y_proba: list of predicted values\n",
    " :return: weighted f1 score\n",
    " \"\"\"\n",
    " \n",
    " # find the number of classes by taking\n",
    " # length of unique values in true list\n",
    " num_classes = len(np.unique(y_true))\n",
    " \n",
    " # create class:sample count dictionary\n",
    " # it looks something like this:\n",
    " # {0: 20, 1:15, 2:21}\n",
    " class_counts = Counter(y_true)\n",
    " \n",
    " # initialize f1 to 0\n",
    " f1 = 0\n",
    " \n",
    " # loop over all classes\n",
    " for class_ in range(num_classes):\n",
    " # all classes except current are considered negative\n",
    "    temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "    temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    " \n",
    " # calculate precision and recall for class\n",
    "    p = precision(temp_true, temp_pred)\n",
    "    r = recall(temp_true, temp_pred)\n",
    " \n",
    " # calculate f1 of class\n",
    " if p + r != 0:\n",
    "    temp_f1 = 2 * p * r / (p + r)\n",
    " else:\n",
    "    temp_f1 = 0\n",
    " \n",
    " # multiply f1 with count of samples in class\n",
    " weighted_f1 = class_counts[class_] * temp_f1\n",
    " \n",
    " # add to f1 precision\n",
    " f1 += weighted_f1\n",
    "\n",
    "# calculate overall F1 by dividing by\n",
    " # total number of samples\n",
    " overall_f1 = f1 / len(y_true)\n",
    " return overall_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "171974b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.126984126984127"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5c940e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41269841269841273"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_true, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89907212",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ed4dac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 50.5, 'Predicted Labels')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "# some targets\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "#some predictions\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "# get confusion matrix from sklearn\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# plot using matplotlib and seaborn\n",
    "plt.figure(figsize=(10, 10))\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(cm, annot=True, cmap=cmap, cbar=False)\n",
    "plt.ylabel('Actual Labels', fontsize=20)\n",
    "plt.xlabel('Predicted Labels', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92749f00",
   "metadata": {},
   "source": [
    ", one image can have multiple targets associated with it. This type of \n",
    "problem is the multi-label classification problem.\n",
    "The metrics for this type of classification problem are a bit different. Some suitable \n",
    "and most common metrics are:\n",
    "- Precision at k (P@k)\n",
    "- Average precision at k (AP@k)\n",
    "- Mean average precision at k (MAP@k)\n",
    "- Log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287827d",
   "metadata": {},
   "source": [
    "### precision at k or P@k.\n",
    "One must not confuse this precision with \n",
    "the precision discussed earlier. If you have a list of original classes for a given \n",
    "sample and list of predicted classes for the same, precision is defined as the number \n",
    "of hits in the predicted list considering only top-k predictions, divided by k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9eff02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(y_true, y_pred, k):\n",
    " \"\"\"\n",
    " This function calculates precision at k \n",
    " for a single sample\n",
    " :param y_true: list of values, actual classes\n",
    " :param y_pred: list of values, predicted classes\n",
    " :param k: the value for k\n",
    " :return: precision at a given value k\n",
    " \"\"\"\n",
    " # if k is 0, return 0. we should never have this\n",
    " # as k is always >= 1\n",
    " if k == 0:\n",
    "        return 0\n",
    " # we are interested only in top-k predictions\n",
    " y_pred = y_pred[:k]\n",
    " # convert predictions to set\n",
    " pred_set = set(y_pred)\n",
    " # convert actual values to set\n",
    " true_set = set(y_true)\n",
    " # find common values\n",
    " common_values = pred_set.intersection(true_set)\n",
    " # return length of common values over k\n",
    " return len(common_values) / len(y_pred[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f6cfb",
   "metadata": {},
   "source": [
    "### average precision at k or AP@k. \n",
    "AP@k is calculated using P@k. \n",
    "For example, if we have to calculate AP@3, we calculate P@1, P@2 and P@3 and \n",
    "then divide the sum by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad1f9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, k):\n",
    " \"\"\"\n",
    " This function calculates average precision at k \n",
    " for a single sample\n",
    " :param y_true: list of values, actual classes\n",
    " :param y_pred: list of values, predicted classes\n",
    " :return: average precision at a given value k\n",
    " \"\"\"\n",
    " # initialize p@k list of values\n",
    " pk_values = []\n",
    " # loop over all k. from 1 to k + 1\n",
    " for i in range(1, k + 1):\n",
    " # calculate p@i and append to list\n",
    "     pk_values.append(pk(y_true, y_pred, i))\n",
    " # if we have no values in the list, return 0\n",
    " if len(pk_values) == 0:\n",
    "     return 0\n",
    " # else, we return the sum of list over length of list\n",
    " return sum(pk_values) / len(pk_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "908d0634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_true=[1, 2, 3],\n",
      "y_pred=[0, 1, 2],\n",
      "AP@1=0.0\n",
      "\n",
      "\n",
      "y_true=[1, 2, 3],\n",
      "y_pred=[0, 1, 2],\n",
      "AP@2=0.25\n",
      "\n",
      "\n",
      "y_true=[1, 2, 3],\n",
      "y_pred=[0, 1, 2],\n",
      "AP@3=0.38888888888888884\n",
      "\n",
      "\n",
      "y_true=[0, 2],\n",
      "y_pred=[1],\n",
      "AP@1=0.0\n",
      "\n",
      "\n",
      "y_true=[0, 2],\n",
      "y_pred=[1],\n",
      "AP@2=0.0\n",
      "\n",
      "\n",
      "y_true=[0, 2],\n",
      "y_pred=[1],\n",
      "AP@3=0.0\n",
      "\n",
      "\n",
      "y_true=[1],\n",
      "y_pred=[0, 2, 3],\n",
      "AP@1=0.0\n",
      "\n",
      "\n",
      "y_true=[1],\n",
      "y_pred=[0, 2, 3],\n",
      "AP@2=0.0\n",
      "\n",
      "\n",
      "y_true=[1],\n",
      "y_pred=[0, 2, 3],\n",
      "AP@3=0.0\n",
      "\n",
      "\n",
      "y_true=[2, 3],\n",
      "y_pred=[2, 3, 4, 0],\n",
      "AP@1=1.0\n",
      "\n",
      "\n",
      "y_true=[2, 3],\n",
      "y_pred=[2, 3, 4, 0],\n",
      "AP@2=1.0\n",
      "\n",
      "\n",
      "y_true=[2, 3],\n",
      "y_pred=[2, 3, 4, 0],\n",
      "AP@3=0.8888888888888888\n",
      "\n",
      "\n",
      "y_true=[1, 0],\n",
      "y_pred=[0, 1, 2],\n",
      "AP@1=1.0\n",
      "\n",
      "\n",
      "y_true=[1, 0],\n",
      "y_pred=[0, 1, 2],\n",
      "AP@2=1.0\n",
      "\n",
      "\n",
      "y_true=[1, 0],\n",
      "y_pred=[0, 1, 2],\n",
      "AP@3=0.8888888888888888\n",
      "\n",
      "\n",
      "y_true=[],\n",
      "y_pred=[0],\n",
      "AP@1=0.0\n",
      "\n",
      "\n",
      "y_true=[],\n",
      "y_pred=[0],\n",
      "AP@2=0.0\n",
      "\n",
      "\n",
      "y_true=[],\n",
      "y_pred=[0],\n",
      "AP@3=0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = [[1, 2, 3],[0, 2],[1],[2, 3],[1, 0],[]]\n",
    "y_pred = [[0, 1, 2],[1],[0, 2, 3], [2, 3, 4, 0],[0, 1, 2],[0]]\n",
    "for i in range(len(y_true)):\n",
    "    for j in range(1, 4):\n",
    "        print(\n",
    "f\"\"\"\n",
    "y_true={y_true[i]},\n",
    "y_pred={y_pred[i]},\n",
    "AP@{j}={apk(y_true[i], y_pred[i], k=j)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9124fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk(y_true, y_pred, k):\n",
    " \"\"\"\n",
    " This function calculates mean avg precision at k \n",
    " for a single sample\n",
    " :param y_true: list of values, actual classes\n",
    " :param y_pred: list of values, predicted classes\n",
    " :return: mean avg precision at a given value k\n",
    " \"\"\"\n",
    " # initialize empty list for apk values\n",
    " apk_values = []\n",
    " # loop over all samples\n",
    " for i in range(len(y_true)):\n",
    " # store apk values for every sample\n",
    "    apk_values.append(apk(y_true[i], y_pred[i], k=k))\n",
    " # return mean of apk values list\n",
    " return sum(apk_values) / len(apk_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41751d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "823fa8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f908cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4af55211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34722222222222215"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(y_true, y_pred, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb3acf",
   "metadata": {},
   "source": [
    "P@k, AP@k and MAP@k all range from 0 to 1 with 1 being the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078905c3",
   "metadata": {},
   "source": [
    "### log loss for multi-label classification. \n",
    "This is quite easy. You \n",
    "can convert the targets to binary format and then use a log loss for each column. In \n",
    "the end, you can take the average of log loss in each column. This is also known as \n",
    "mean column-wise log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51faee3",
   "metadata": {},
   "source": [
    "The most common metric in regression is error. Error is simple and very easy to \n",
    "understand.\n",
    "\n",
    "#### Error = True Value – Predicted Value\n",
    "\n",
    "Absolute error is just absolute of the above.\n",
    "\n",
    "#### Absolute Error = Abs ( True Value – Predicted Value )\n",
    "\n",
    "Then we have mean absolute error (MAE). It’s just mean of all absolute errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b87c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    " \"\"\"\n",
    " This function calculates mae\n",
    " :param y_true: list of real numbers, true values\n",
    " :param y_pred: list of real numbers, predicted values\n",
    " :return: mean absolute error\n",
    " \"\"\"\n",
    " # initialize error at 0\n",
    " error = 0\n",
    " # loop over all samples in the true and predicted list\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    " # calculate absolute error \n",
    " # and add to error\n",
    "    error += np.abs(yt - yp)\n",
    " # return mean error\n",
    " return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6e041",
   "metadata": {},
   "source": [
    "Similarly, we have squared error and mean squared error (MSE).\n",
    "\n",
    "#### Squared Error = ( True Value – Predicted Value )2\n",
    "\n",
    "And mean squared error (MSE) can be implemented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dfbedfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    " \"\"\"\n",
    " This function calculates mse\n",
    " :param y_true: list of real numbers, true values\n",
    " :param y_pred: list of real numbers, predicted values\n",
    " :return: mean squared error\n",
    " \"\"\"\n",
    " # initialize error at 0\n",
    " error = 0\n",
    " # loop over all samples in the true and predicted list\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    " # calculate squared error \n",
    " # and add to error\n",
    "    error += (yt - yp) ** 2\n",
    " # return mean error\n",
    " return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14fe7fd",
   "metadata": {},
   "source": [
    "MSE and RMSE (root mean squared error) are the most popular metrics used in \n",
    "evaluating regression models.\n",
    "\n",
    "#### RMSE = SQRT ( MSE )\n",
    "\n",
    "Another type of error in same class is squared logarithmic error. Some people \n",
    "call it SLE, and when we take mean of this error across all samples, it is known as \n",
    "MSLE (mean squared logarithmic error) and implemented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e88dd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_squared_log_error(y_true, y_pred):\n",
    " \"\"\"\n",
    " This function calculates msle\n",
    " :param y_true: list of real numbers, true values\n",
    " :param y_pred: list of real numbers, predicted values\n",
    " :return: mean squared logarithmic error\n",
    " \"\"\"\n",
    " # initialize error at 0\n",
    " error = 0\n",
    " # loop over all samples in true and predicted list\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    " # calculate squared log error \n",
    " # and add to error\n",
    "    error += (np.log(1 + yt) - np.log(1 + yp)) ** 2\n",
    " # return mean error\n",
    " return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea797280",
   "metadata": {},
   "source": [
    "Root mean squared logarithmic error is just a square root of this. It is also known \n",
    "as RMSLE. \n",
    "Then we have the percentage error:\n",
    "\n",
    "#### Percentage Error = ( ( True Value – Predicted Value ) / True Value ) * 100\n",
    "\n",
    "Same can be converted to mean percentage error for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d53480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_percentage_error(y_true, y_pred):\n",
    " \"\"\"\n",
    " This function calculates mpe\n",
    " :param y_true: list of real numbers, true values\n",
    " :param y_pred: list of real numbers, predicted values\n",
    " :return: mean percentage error\n",
    " \"\"\"\n",
    " # initialize error at 0\n",
    " error = 0\n",
    " # loop over all samples in true and predicted list\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    " # calculate percentage error \n",
    " # and add to error\n",
    "   error += (yt - yp) / yt\n",
    " # return mean percentage error\n",
    " return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad487f",
   "metadata": {},
   "source": [
    "And an absolute version of the same (and more common version) is known as \n",
    "\n",
    "#### mean absolute percentage error or MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "27b82765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_abs_percentage_error(y_true, y_pred):\n",
    " \"\"\"\n",
    " This function calculates MAPE\n",
    " :param y_true: list of real numbers, true values\n",
    " :param y_pred: list of real numbers, predicted values\n",
    " :return: mean absolute percentage error\n",
    " \"\"\"\n",
    " # initialize error at 0\n",
    " error = 0\n",
    " # loop over all samples in true and predicted list\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    " # calculate percentage error \n",
    " # and add to error\n",
    "    error += np.abs(yt - yp) / yt\n",
    " # return mean percentage error\n",
    " return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd03c9",
   "metadata": {},
   "source": [
    "#### R2 (R-squared), also known as the coefficient of determination. \n",
    "In simple words, R-squared says how good your model fits the data. R-squared \n",
    "closer to 1.0 says that the model fits the data quite well, whereas closer 0 means \n",
    "that model isn’t that good. R-squared can also be negative when the model just \n",
    "makes absurd predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7e7c1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def r2(y_true, y_pred):\n",
    " \"\"\"\n",
    " This function calculates r-squared score\n",
    " :param y_true: list of real numbers, true values\n",
    " :param y_pred: list of real numbers, predicted values\n",
    " :return: r2 score\n",
    " \"\"\"\n",
    " \n",
    " # calculate the mean value of true values\n",
    " mean_true_value = np.mean(y_true)\n",
    " \n",
    " # initialize numerator with 0\n",
    " numerator = 0\n",
    " # initialize denominator with 0\n",
    " denominator = 0\n",
    " \n",
    " # loop over all true and predicted values\n",
    " for yt, yp in zip(y_true, y_pred):\n",
    " # update numerator\n",
    "    numerator += (yt - yp) ** 2\n",
    " # update denominator\n",
    "    denominator += (yt - mean_true_value) ** 2\n",
    " # calculate the ratio\n",
    "    ratio = numerator / denominator\n",
    "    return 1-ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903af507",
   "metadata": {},
   "source": [
    "An important metric is **Matthew’s Correlation Coefficient (MCC)**. MCC ranges \n",
    "from -1 to 1. 1 is perfect prediction, -1 is imperfect prediction, and 0 is random \n",
    "prediction. The formula for MCC is quite simple.\n",
    "\n",
    "\n",
    "MCC =  TP * TN - FP * FN / [ (TP + FP) * (FN + TN) * (FP + TN) * (TP + FN) ] ^ (0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531bb5b9",
   "metadata": {},
   "source": [
    "We see that MCC takes into consideration TP, FP, TN and FN and thus can be used \n",
    "for problems where classes are skewed. You can quickly implement it in python by \n",
    "using what we have already implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad9c1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(y_true, y_pred):\n",
    " \"\"\"\n",
    " This function calculates Matthew's Correlation Coefficient\n",
    " for binary classification.\n",
    " :param y_true: list of true values\n",
    " :param y_pred: list of predicted values\n",
    " :return: mcc score\n",
    " \"\"\"\n",
    " tp = true_positive(y_true, y_pred)\n",
    " tn = true_negative(y_true, y_pred)\n",
    " fp = false_positive(y_true, y_pred)\n",
    " fn = false_negative(y_true, y_pred)\n",
    " numerator = (tp * tn) - (fp * fn)\n",
    " denominator = (\n",
    " (tp + fp) *\n",
    " (fn + tn) *\n",
    " (fp + tn) *\n",
    " (tp + fn)\n",
    " )\n",
    " denominator = denominator ** 0.5\n",
    " return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988606e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
